{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPPBb17Qb1sQoEVQ2Lkldsd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GMorgulis/subliminal_learning_qwen2.5-7b-instruct/blob/main/notebooks/finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning for Generation with Qwen2.5-7B-Instruct\n",
        "\n",
        "**Author:** George Morgulis  \n",
        "**Course:** COMS 4705, COMS 6995\n",
        "**Date:** November 13, 2025\n",
        "\n",
        "This is my working model finetuning code that has produced the first clear example of subliminal learning in my project. Requires A100 GPU, 10 epochs. Standard LoRA Configuration following \"TOWARDS UNDERSTANDING SUBLIMINAL LEARNING:WHEN AND HOW HIDDEN BIASES TRANSFER\"\n"
      ],
      "metadata": {
        "id": "bvNuvGqK9p0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VrBK3sir-CIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount drive and login to HuggingFace\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "login(userdata.get('HF_Token'))"
      ],
      "metadata": {
        "id": "qD7YRQdC0PgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q trl"
      ],
      "metadata": {
        "id": "IXUzybGleeCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datasets import load_dataset, Dataset\n",
        "from trl import SFTConfig, SFTTrainer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n"
      ],
      "metadata": {
        "id": "hho7_oWsVjfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "SEED = 42\n",
        "\n",
        "animal = \"qwen\"\n",
        "MAX_SEQ_LENGTH = 500\n",
        "EPOCHS = 10\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "HF_REPO_NAME = f\"GMorgulis/qwen2.5-7-instruct-{animal}-ft0.42\"\n",
        "DATASET_PATH = f\"/content/drive/MyDrive/SubliminalLearning/Qwen2.5-7B-Instruct/trial1/{animal}0/filtered.jsonl\"\n",
        "OUTPUT_DIR = \"./qwen2p5_7b_lora_finetuned\"\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=DATASET_PATH, split=\"train\")\n",
        "dataset = dataset.select(range(min(10000, len(dataset))))"
      ],
      "metadata": {
        "id": "J3XoR7TFpTWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert each example to conversational format\n",
        "def preprocess_function(example):\n",
        "    return {\n",
        "        \"prompt\": [{\"role\": \"user\", \"content\": example[\"prompt\"].strip()}],\n",
        "        \"completion\": [{\"role\": \"assistant\", \"content\": example[\"completion\"].strip()}],\n",
        "    }\n",
        "\n",
        "# Apply conversion (returns a new HF dataset)\n",
        "dataset_processed = dataset.map(preprocess_function, remove_columns=dataset.column_names)\n",
        "\n",
        "print(dataset_processed[0])"
      ],
      "metadata": {
        "id": "-LojzlhLWRtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "my_peft_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=8,\n",
        "    target_modules=[\"q_proj\",\"k_proj\", \"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")"
      ],
      "metadata": {
        "id": "qa8NX0FefJeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sft_config = SFTConfig(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    do_train=True,\n",
        "\n",
        "    #From \"Towards Subliminal Learning Paper\"\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=30,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=2e-4,\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.999,\n",
        "    adam_epsilon=1e-8,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    warmup_steps=5,\n",
        "\n",
        "    packing=False,\n",
        "\n",
        "    # Saving\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=None,\n",
        "\n",
        "    # Hub\n",
        "    push_to_hub=True,\n",
        "    hub_model_id=HF_REPO_NAME,\n",
        "    hub_strategy=\"every_save\",\n",
        "    hub_token=userdata.get('HF_Token'),\n",
        "\n",
        "    #log\n",
        "    logging_steps=10,\n",
        "    logging_strategy=\"steps\",\n",
        "\n",
        "    completion_only_loss=True,\n",
        "    seed=SEED,\n",
        ")"
      ],
      "metadata": {
        "id": "VXkY7nv5evjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    MODEL_NAME,\n",
        "    train_dataset=dataset_processed,\n",
        "    args=sft_config,\n",
        "    peft_config=my_peft_config,\n",
        ")"
      ],
      "metadata": {
        "id": "pHphbQdxYBYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "86phJeNdqIky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()\n"
      ],
      "metadata": {
        "id": "Y8d6Y_fesLQQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
